#MicroServices - Scaler Master Class

Types of Archeture
1) Monolithic 2) Microservie

Monolithic - A traditional model of a software program, which is built as a unified unit that is self-contained and independent from other applications.

let's see pros and cons of Monolithic
Monolithic Pros - Very Easy to manage, Easy deployment, One code base.
Monolithic Cons - Single Point of Failure, If load increase, waiting time increases. you always need of backup.

Every product start with monolithic because of low budget.

Scaling - easily increase or decrease your computing resources as needed
There are two main types of scaling in the cloud: vertical scaling and horizontal scaling.

Vertical Scaling:
Vertical scaling involves increasing the capacity of a single virtual machine (VM) or server by adding more resources such as CPU, RAM, or storage

Horizontal Scaling:
Horizontal scaling involves adding more instances of a resource, such as virtual machines or containers, to distribute the load

 Flipkart Analogy:
When it started in 2008 it might getting 10 Orders per day.
and 2 years later in 2010 - 1000 Orders per day

Now 1 normal server is not enough so replaced with 1 super computer(server) (- rich in resources).
this is nothing but vertical scaling. and it has it's limitation it's not infinite scalable.
we can not always bring bigger compter.

Now instead of upgrading what flipkart brought 20 new compuers(servers).
Now same code running on 20 instances.

Now we can not hard 20 IP address in frontend. (20 is also not fixed number it would be always changing).
so to solve this issue we have something called as Load Balanncer.

Load Balancer - the device or service that sits between the user and the server group and acts as an invisible facilitator, ensuring that all resource servers are used equally.

then load balncer becomes SPOF (Single Point of failure)
load balancer also has many replicas.

and how it works ? Round Robin most of the time. if req distribution algo is heavy then itself becomes problem.
load balancer keeps a check server if it is dead it remove from list so always keeps light algo.

puting everything (codebase) in each server is not always good - we don't get optionality of selecting scaling.
eg. take flipkart example. 
product display service will require more computing power than payment. (because not all products are viewed are purchased).

so cons of this approach -->
--> No Selective scaling
--> No independence of technology
--> if size is more new program find difficult to understand 
--> Build and runtime is will also slow.
--> developer productivity reduce.

pros --> Easy to handle
     --> Module to Module call is just method call (In case of Micro service N/w Comes in betwween)
  
So monolothic are lower latency and can save lot of money. (No Network calls).
Speed is not always concerns of every application some prefered security over it such as banks.

Microservices - A microservices architecture is a type of application architecture where the application is developed as a collection of services.
It provides the framework to develop, deploy, and maintain microservices architecture diagrams and services independently.

word Microservices just came into picture few years back but companies using this more than 15 years ago.

pros - 
1) selective scaling possible. 
Now we can have 5 service running for product and 2 service for payment.
And each service can be written in diffrent proogramming language.

why is is possible talking to other app via n/w
--> so you talking in language nuetral protocal (Json Resp) can be read by every prog language.

2) Size of Each Application will be smaller - Build Time & Run Time (App Start Time)
3) Understanding Codebase is much easier
4) 24x7 you don't need big machine 

Cons:
1) latency will increase
2) Infrastructure overhead will be increasing
if you use 'n' number of programming language you will also required developer to understand 'n' number of programming language.
3) We have 3 Network hops now.

Ways of communication between Microservice 
1) Http  2) RPC  3) Messaging Queue

HTTP - HTTP is synchronous and the responses come in the requested order, no matter if the system is asynchronous it will be ineffective.
This is why HTTP should not be used as a backend for microservices.

/***********************************************************************************/
Multiple Application - 
Earlier LB job was wasy route to any server now in micro service it is not possible.
PG req can not handle by auth service.
so how to identify correct service for request ? ---> Use URL

flipkart.cmo/product  --> Product Listing 
flipkart.cmo/pay  --> Payment Gateway
flipkart.cmo/orders --> Order Service.

We introduce new layer called API Gateway layer.
API gateway will read requirement so it will forward request to Load Balancer.

API Gateway also does the other things 
1) Rate Limiter
2) sometime also manage authencation 


                           ---> LB ----> Multiple Auth Server
Client -->  API Gateway ---
                           ---> LB ----> Multiple PG Server

Usage of Http ends at API gatwwat inside we don't use HTTP and JSON for communication internally we use some better stuff.

Serialisation: In computing, serialization (or serialisation) is the process of translating a data structure or object state into a format that can be stored.
eg converting Java Object to JSON in API for browsers or end users.

ProtoBuf:- Protocol Buffers are language-neutral, platform-neutral extensible mechanisms for serializing structured data.
             
           HTTP
client ---------------> API G/W --------------->  (Internally Protobuf used instead of JSON)

HTTP is very heavy protocol.
HTTP is also add additional overhead.

why not use internally better protocol ?
- grpc (remote procedure call) - Use for interserver communication.
 - most browser don't support RPC that's why we still use HTTP.

gRPC is a high-performance, open-source RPC (remote procedure call) framework that can be used to build microservices.
It uses HTTP/2 for transport and Protocol Buffers as the interface description language.

So Instead of HTTP ---> GRPC  and JSON ---> ProtoBuf

Communication between Microservice
1) HTTP  2) RPC  3) Messaging Queue

Event Driven Architecture(KAFKA)
1) Distributed Transaction

Communication Ways : 1) Sync 2)Async 3)Event Driven

suppose we have two services 1) Product Service   2) User Service

Sync: Product service will not be able to serve it's users unless service respond to it. so here we need to make sync call.
payments process part handle by both part and you want two service cordinated payment process.

ASync: News Feed Service of Instagram (Recent Post)
As my friend can be present in db1 or db2 so service needs to look all db copy because my friend present across dbs.
Here we make request and do some other work (Async way)

Event Driven Communication:- Analogy river flowing from Hill. Queue is River 
 1st part is producer - create an info or create an even 
 2nd part is consumer - like to do some action based on event.

eg. Auth Service - 
On 'Sign Up' Event Email ----------------------> Notification Server Interested in event and send email.
Consumer has subscribed to perticular type of event when it receives some event it will do the work.

Beauty of Message Queue is it will keeps the task untill consume.
Auth Seriver 10 Server ------------Event Queue-------------------> 2 Notification Service

MQ can also have multiple copies, typically 7 days retension policy.

Distrubuted Transaction:
ACID: Automacity, Consistency, Isolation, Durability

Automacity - when you are running a req of db query it should look single query.

Bank Transaction A ---500r---> B

1) Get Current Balancer
2) check if > 500
3) if No ---> abort
4) set balance as current = current - 500
5) get balancer of B
6) B =+ 500

Now chance at any point server can crash or bad thing happen let's say at worst case if failed at step 4 :(

to solve this DB uses lock rows on which opearation needs to perform.
A & B copy in some other rows perform operation there brign back values

this is fine for single db.

what about distributed db? 
1 row is present in another table and another row is present in another table. and they are present in diffrent db machines

Implementing locking across is inconsistent.
1 machine recivers signal other might not due to n/w failure so it will rollback.

we have another method two phase commit 
lock rows in both db only release after I receive ack from both.

fine but we have to pay penalty of bad user experaice due to n/w delay. so this is also not good option

solution is SAGA pattern
1) orchestration 
2) choreography
 
